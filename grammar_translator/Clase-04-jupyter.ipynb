{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsers para Gramáticas independientes de contexto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recursive Descent Parser\n",
    "\n",
    "def rd_parser(oracion, gramatica):                  # Definimos una función llamada rd_parser con dos argumentos.\n",
    "    oracion = oracion.lower()                       # Convertimos a minúscula la oración utilizando una función nativa de la cadena de caracteres: lower(). \n",
    "        \n",
    "    if oracion.endswith('.'):                       # Otra función nativa de las strings nos ayuda a chequear si la cadena termina en x argumento.\n",
    "        oracion = re.sub('\\.',' ',oracion)          # En este caso, si la oración termina con un punto, se lo quita utilizando la librería de expresiones regulares \"re\".\n",
    "    else:                                           # Si no termina con un punto, \n",
    "        oracion = oracion                           # toma la oración como estaba originalmente.\n",
    "    lista_palabras = oracion.split()              # Dividimos la oración en palabras tomando como separador el espacio en blanco  con otra función nativa de las strings: split.\n",
    "    print(\"- Esta es la lista de palabras resultante: \", lista_palabras) # Split nos devuelve una lista (ordenada) de strings.\n",
    "      \n",
    "    gramatica = nltk.data.load(gramatica)           # Usamos la función de la sub librería \"data\" que nos permite cargar una gramática para que pueda ser usada luego por el parser.    \n",
    "    rd_parser = nltk.RecursiveDescentParser(gramatica) # Instanciamos la clase del parser que nos da NLTK pasandole un argumento obligatorio: la gramática.\n",
    "    for arbol in rd_parser.parse(lista_palabras):    # Una vez que instanciamos la clase, podemos usar sus funciones mientras le pasemos los argumentos requeridos. En este caso, usamos la función \"parser\" a la que le pasaremos nuestra lista de palabras, y la función nos devolverá cada árbol posible en mi gramática para esa oración.\n",
    "        print(\"- Este es el árbol resultante: \", arbol.draw()) # Imprimimos cada árbol en la consola."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para correr el Recursive Descent Parser\n",
    "\n",
    "print('Escribí una oración:')                          # Para que me pida que escriba una oración\n",
    "oracion1 = input()                                     # Para que me abra un campo en el que escriba la oración\n",
    "gramatica = 'gramaticas/prueba2.cfg'                       # Indicamos el path a nuestra gramatica\n",
    "rd_parser(oracion1, gramatica)                         # Llamamos a la función que creamos con los dos argumentos que establecimos como obligatorios.\n",
    "\n",
    "# Oraciones que acepta la gramática: \n",
    "# Cata/Martín/Julia/Maca/Pablo fuma\n",
    "# Cata/Martín/Julia/Maca/Pablo entregó/envió el/la/un/una plaza/facultad/regalo/globo/tabaco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primera iteraciòn: todas las reglas que contengan la categorìa\n",
    "# Segunda iteraciòn: borrar todas las reglas que no tengan nodo terminal\n",
    "{'SV': ['FV', 'FV SP', 'V']}\n",
    "{'SV': ['SV -> FV', 'FV SP', 'V']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_given_categorial_grammar_when_translator_runs_then_return_CFG():\n",
    "        expected: \"\"\"S -> SN SV\n",
    "        SN -> PRO\n",
    "        SN -> D NC\n",
    "        SN -> NP\n",
    "        NP ->  'julia' | 'cata' | 'fede' | 'martín' | 'pablo' | 'fer' | 'vicky'\n",
    "        NC -> 'regalo' | 'globo' | 'plaza' | 'facultad' | 'tabaco'\n",
    "        D -> 'el' | 'la' | 'una' | 'un'\n",
    "        PRO -> 'él' | 'ella'\n",
    "        PART -> 'enviado' | 'entregado' | 'explotado' | 'fumado'\n",
    "        IV -> 'fuma' | 'habla'\n",
    "        TV -> 'fumó' | 'explotó'\n",
    "        DTV -> 'envió' | 'entregó'\n",
    "        SV -> TV SN\n",
    "        SV -> DTV SN\n",
    "        SV -> DTV SN SN\n",
    "        SV -> IV\n",
    "        SV -> FV\n",
    "        SV -> FV SP\n",
    "        SV -> FV SN\n",
    "        FV -> AUX PART\n",
    "        FV -> DTV\n",
    "        AUX -> 'fue'\n",
    "        SP -> P SN\n",
    "        P -> 'a' | 'por' | 'en'\"\"\"\n",
    "        categorial = \"\"\":- S, NP, NC, PARTP, PP\n",
    "            D :: NP/NC\n",
    "            PRO :: NP\n",
    "\n",
    "            TV :: (S\\NP)/NP\n",
    "            DTV :: TV/PP\n",
    "\n",
    "\n",
    "            el => D\n",
    "            la => D\n",
    "            una => D\n",
    "            un => D\n",
    "\n",
    "            julia => NP\n",
    "            cata => NP\n",
    "            fede => NP\n",
    "            martín => NP\n",
    "            pablo => NP\n",
    "            fer => NP\n",
    "            vicky => NP\n",
    "\n",
    "            él => PRO\n",
    "            ella => PRO\n",
    "\n",
    "            regalo => NC\n",
    "            globo => NC\n",
    "            plaza => NC\n",
    "            facultad => NC\n",
    "            tabaco => NC\n",
    "\n",
    "            fuma => S\\NP\n",
    "\n",
    "            fumó => TV\n",
    "            explotó => TV\n",
    "\n",
    "            envió => DTV\n",
    "            entregó => DTV\n",
    "\n",
    "            a => PP/NP\n",
    "            por => PP/NP\n",
    "            en => PP/NP\n",
    "\n",
    "            fumado => PARTP/PP\n",
    "            enviado => PARTP/PP\n",
    "            entregado => PARTP/PP\n",
    "            explotado => PARTP/PP\n",
    "\n",
    "            fue => (S\\NP)/PARTP\n",
    "\n",
    "            explotó => S\\NP\n",
    "            habla => S\\NP\n",
    "            \"\"\"\n",
    "        result = translator(categorial)\n",
    "        assert result == expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{% include additional_content.html %}\n",
    "\n",
    "{% include copybutton.html %}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S -> SN SV\n",
      "SN -> PRO\n",
      "SN -> D NC\n",
      "SN -> NP\n",
      "NP ->  'julia' | 'cata' | 'fede' | 'martÃ­n' | 'pablo' | 'fer' | 'vicky'\n",
      "NC -> 'regalo' | 'globo' | 'plaza' | 'facultad' | 'tabaco'\n",
      "D -> 'el' | 'la' | 'una' | 'un'\n",
      "PRO -> 'Ã©l' | 'ella'\n",
      "PART -> 'enviado' | 'entregado' | 'explotado' | 'fumado'\n",
      "IV -> 'fuma' | 'habla'\n",
      "TV -> 'fumÃ³' | 'explotÃ³'\n",
      "DTV -> 'enviÃ³' | 'entregÃ³'\n",
      "SV -> TV SN\n",
      "SV -> DTV SN\n",
      "SV -> DTV SN SN\n",
      "SV -> IV\n",
      "SV -> FV\n",
      "SV -> FV SP\n",
      "SV -> FV SN\n",
      "FV -> AUX PART\n",
      "FV -> DTV\n",
      "AUX -> 'fue'\n",
      "SP -> P SN\n",
      "P -> 'a' | 'por' | 'en'\n",
      "\n",
      "\n",
      "['S -> SN SV', 'SN -> PRO', 'SN -> D NC', 'SN -> NP', \"NP ->  'julia' | 'cata' | 'fede' | 'martÃ\\xadn' | 'pablo' | 'fer' | 'vicky'\", \"NC -> 'regalo' | 'globo' | 'plaza' | 'facultad' | 'tabaco'\", \"D -> 'el' | 'la' | 'una' | 'un'\", \"PRO -> 'Ã©l' | 'ella'\", \"PART -> 'enviado' | 'entregado' | 'explotado' | 'fumado'\", \"IV -> 'fuma' | 'habla'\", \"TV -> 'fumÃ³' | 'explotÃ³'\", \"DTV -> 'enviÃ³' | 'entregÃ³'\", 'SV -> TV SN', 'SV -> DTV SN', 'SV -> DTV SN SN', 'SV -> IV', 'SV -> FV', 'SV -> FV SP', 'SV -> FV SN', 'FV -> AUX PART', 'FV -> DTV', \"AUX -> 'fue'\", 'SP -> P SN', \"P -> 'a' | 'por' | 'en'\", '', '']\n",
      "SN -> PRO\n"
     ]
    }
   ],
   "source": [
    "#Abrir y leer gramática\n",
    "with open('gramaticas/prueba2.cfg') as archivo:\n",
    "    gram = archivo.read()\n",
    "print(gram)    \n",
    "# guardarla en una lista separada por lineas\n",
    "list = gram.split(\"\\n\")\n",
    "print(list)\n",
    "print(list[1])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Asi quedaria cada elemento en el diccionario{'SN': 'PRO'}\n",
      "['S', ' SN SV']\n",
      "['SN', ' PRO']\n",
      "['SN', ' D NC']\n",
      "['SN', ' NP']\n",
      "['NP', \"  'julia' | 'cata' | 'fede' | 'martÃ\\xadn' | 'pablo' | 'fer' | 'vicky'\"]\n",
      "['NC', \" 'regalo' | 'globo' | 'plaza' | 'facultad' | 'tabaco'\"]\n",
      "['D', \" 'el' | 'la' | 'una' | 'un'\"]\n",
      "['PRO', \" 'Ã©l' | 'ella'\"]\n",
      "['PART', \" 'enviado' | 'entregado' | 'explotado' | 'fumado'\"]\n",
      "['IV', \" 'fuma' | 'habla'\"]\n",
      "['TV', \" 'fumÃ³' | 'explotÃ³'\"]\n",
      "['DTV', \" 'enviÃ³' | 'entregÃ³'\"]\n",
      "['SV', ' TV SN']\n",
      "['SV', ' DTV SN']\n",
      "['SV', ' DTV SN SN']\n",
      "['SV', ' IV']\n",
      "['SV', ' FV']\n",
      "['SV', ' FV SP']\n",
      "['SV', ' FV SN']\n",
      "['FV', ' AUX PART']\n",
      "['FV', ' DTV']\n",
      "['AUX', \" 'fue'\"]\n",
      "['SP', ' P SN']\n",
      "['P', \" 'a' | 'por' | 'en'\"]\n",
      "['']\n",
      "['']\n",
      "[['S', ' SN SV'], ['SN', ' PRO'], ['SN', ' D NC'], ['SN', ' NP'], ['NP', \"  'julia' | 'cata' | 'fede' | 'martÃ\\xadn' | 'pablo' | 'fer' | 'vicky'\"], ['NC', \" 'regalo' | 'globo' | 'plaza' | 'facultad' | 'tabaco'\"], ['D', \" 'el' | 'la' | 'una' | 'un'\"], ['PRO', \" 'Ã©l' | 'ella'\"], ['PART', \" 'enviado' | 'entregado' | 'explotado' | 'fumado'\"], ['IV', \" 'fuma' | 'habla'\"], ['TV', \" 'fumÃ³' | 'explotÃ³'\"], ['DTV', \" 'enviÃ³' | 'entregÃ³'\"], ['SV', ' TV SN'], ['SV', ' DTV SN'], ['SV', ' DTV SN SN'], ['SV', ' IV'], ['SV', ' FV'], ['SV', ' FV SP'], ['SV', ' FV SN'], ['FV', ' AUX PART'], ['FV', ' DTV'], ['AUX', \" 'fue'\"], ['SP', ' P SN'], ['P', \" 'a' | 'por' | 'en'\"], [''], ['']]\n"
     ]
    }
   ],
   "source": [
    "#Dividir cada regla \n",
    "sn = list[1].split(\"->\")\n",
    "#print(sn)\n",
    "\n",
    "# pasar los items del banco de reglas a un diccionario \n",
    "dict = {}\n",
    "dict[sn[0].strip()] = sn[1].strip()\n",
    "print(f\" Asi quedaria cada elemento en el diccionario{dict}\")\n",
    "\n",
    "\n",
    "#Agregar los elementos del banco a una lista de listas \n",
    "listaSplit=[]\n",
    "\n",
    "for item in list:\n",
    "    result = item.split(\"->\")\n",
    "    result[0]=result[0].strip()\n",
    "    print(result)\n",
    "    listaSplit.append(result)\n",
    "    \n",
    "print(listaSplit)\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertir lista en string y guardar la gramática resultante en un archivo\n",
    "result = \"\\n\".join(list)\n",
    "with open('gramaticas/output.txt','w+') as out:\n",
    "    out.write(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
